{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64249dda",
   "metadata": {},
   "source": [
    "# Creating a Random Forest Classification Model. \n",
    "\n",
    "## Bottom Line Up Front: \n",
    "\n",
    "The correlation of the features are too low to get more accurate predictions. Currently predicting at 54% at best, might as well be a coin flip to predict who would churn or not.\n",
    "\n",
    " We need to collect better data. \n",
    "\n",
    "***Recommendation***\n",
    "\n",
    "I suggest the following: \n",
    "    - Actual Income amount, not just Low/Medium/High. This would have helped narrow down the tax bracket the customers who churn fall in, and tease out a potential reason for churning. \n",
    "    - Monthly spending to see if it is increasing, decreasing or flat.   Might offer insight into predicting who will churn. \n",
    "    - Interaction Quality not just count or resolved. Would answer how the customer felt when it was resolved. Ties in with Monthly Spending, did their spending decrease after an issue was reported, or after it stayed unresolved. \n",
    "    - Check if feedback is positive or negative. \n",
    "    - Consider noSQL to store what the feedback or complaint is, what are they inquiring about to see if customers who churn have the same issue.\n",
    "    - When was the issue reported, when was it resolved. Time to resolution would help me understand better if our customer wait times might be a problem. \n",
    "    - Login dates, not just frequency of login, would be helpful to see if they were logging in a lot at first then suddenly stopped, and maybe we can find out why they stopped by checking the correlation with the above feature recommendations. \n",
    "\n",
    "The current dataset captures what customers do but not how they feel about the service. I can calculate Customer Satisfaction Scores from the above features and see how that correlates to churn. \n",
    "\n",
    "With the actual income, I can determine what customers earning churn because from the clustering data, it seems like the lower earners, who spend the most are the ones leaving more so that those who login frequently and spend and complain less. See previous report for more detail. \n",
    "\n",
    "## Algorithm Selection\n",
    "Using Random Forest because while accuracy is important, the task specifies that the model must be interpretable to the stakeholders.\n",
    "Random Forest indicates which features mattered most in the decisions and we can show this to stakeholders that this is why the model made a prediction.\n",
    "\n",
    "XG Boost would be the most accurate, but lacks the interpretable aspect, with each decision tree correcting the one before it, tracing the specific prediction becomes tangled. Logistic Regression will be the easiest to explain but will not be as accurate as random forest. \n",
    "\n",
    "## Implementation:\n",
    "    - I will train the model on 80% of the available Customer_Data_Cleaned set and test it on the remaining 20%.\n",
    "\n",
    "    - target (y) is ChurnStatus. \n",
    "\n",
    "    - features (x) are all features except CustomerID because it's not important to the analysis, has no bearing whatsoever. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24c91821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install libraries\n",
    "!python -m pip install --upgrade pip -q\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn openpyxl -q\n",
    "!pip install --upgrade openpyxl -q\n",
    "!pip install xgboost -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "072b4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2979ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   CustomerID                   1000 non-null   int64  \n",
      " 1   Age                          1000 non-null   int64  \n",
      " 2   isMale                       1000 non-null   int64  \n",
      " 3   IncomeLevel                  1000 non-null   int64  \n",
      " 4   ChurnStatus                  1000 non-null   int64  \n",
      " 5   TotalSpent                   1000 non-null   float64\n",
      " 6   MinTransaction               1000 non-null   float64\n",
      " 7   MaxTransaction               1000 non-null   float64\n",
      " 8   TransactionFrequency         1000 non-null   int64  \n",
      " 9   LoyaltyLength                1000 non-null   int64  \n",
      " 10  InquiryCount                 1000 non-null   int64  \n",
      " 11  InquiryResolved              1000 non-null   int64  \n",
      " 12  InquiryUnresolved            1000 non-null   int64  \n",
      " 13  FeedbackCount                1000 non-null   int64  \n",
      " 14  FeedbackResolved             1000 non-null   int64  \n",
      " 15  FeedbackUnresolved           1000 non-null   int64  \n",
      " 16  ComplaintCount               1000 non-null   int64  \n",
      " 17  ComplaintResolved            1000 non-null   int64  \n",
      " 18  ComplaintUnresolved          1000 non-null   int64  \n",
      " 19  LoginFrequency               1000 non-null   int64  \n",
      " 20  MaritalStatus_Divorced       1000 non-null   int64  \n",
      " 21  MaritalStatus_Married        1000 non-null   int64  \n",
      " 22  MaritalStatus_Single         1000 non-null   int64  \n",
      " 23  MaritalStatus_Widowed        1000 non-null   int64  \n",
      " 24  ServiceUsage_Mobile App      1000 non-null   int64  \n",
      " 25  ServiceUsage_Online Banking  1000 non-null   int64  \n",
      " 26  ServiceUsage_Website         1000 non-null   int64  \n",
      "dtypes: float64(3), int64(24)\n",
      "memory usage: 211.1 KB\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) # Set option to display all columns\n",
    "pd.set_option('display.float_format', '{:.2f}'.format) # Set float format to 2 decimal places\n",
    "\n",
    "# Load the cleaned customer data we previously created, and verify the info and the first few rows\n",
    "Customer_Data = pd.read_excel('Customer_Data_Cleaned.xlsx')\n",
    "Customer_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "836307fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "\n",
    "X = Customer_Data.drop(columns=['CustomerID', 'ChurnStatus'])\n",
    "y = Customer_Data['ChurnStatus']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, # 20% for testing\n",
    "                                                    random_state=42, # makes it reproducible same split every time\n",
    "                                                    stratify= y # keep churn ratio distributed and balanced in both sets\n",
    "                                                    )\n",
    "\n",
    "# Scale the X_train and X_test data using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train = X_train_scaled\n",
    "X_test_scaled= scaler.transform(X_test)\n",
    "X_test = X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf0729",
   "metadata": {},
   "source": [
    "***Reasoning:***\n",
    "\n",
    "When creating the for loop to check for hyperparameters, I could have used GridSearchCV but I wanted to evaluate for false alarms as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "400cb883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best settings: {'trees': 500, 'depth': 10, 'weight': 5, 'threshold': 0.3, 'caught': np.int64(20), 'false_alarms': np.int64(76)}\n",
      "Recall: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Create the for loop to tune hyperparameters\n",
    "best_recall = 0\n",
    "best_settings = {}\n",
    "\n",
    "for n_trees in [100, 200, 500]: # select number of trees\n",
    "    for depth in [5, 10, 20, None]: # select max depth\n",
    "        for weight in [1, 2, 5, 10]: # select class weight for churners\n",
    "            for threshold in [0.3, 0.4, 0.5]: # select probability threshold\n",
    "                model = RandomForestClassifier(n_estimators=n_trees, \n",
    "                                                max_depth=depth, \n",
    "                                                class_weight={0: 1, 1: weight},\n",
    "                                                random_state=42) # random state for reproducibility\n",
    "                model.fit(X_train, y_train)\n",
    "                probs = model.predict_proba(X_test)[:, 1]\n",
    "                predictions = (probs >= threshold).astype(int)\n",
    "                \n",
    "                caught = confusion_matrix(y_test, predictions)[1, 1]\n",
    "                false_alarms = confusion_matrix(y_test, predictions)[0, 1]\n",
    "                recall = caught / 41 # there are 41 actual churners in the test set, caught divided by total actual churners\n",
    "                \n",
    "                # Only save if this is the best so far AND false alarms are reasonable\n",
    "                if recall > best_recall and false_alarms < 80: # stop if more than 80 false alarms, store settings\n",
    "                    best_recall = recall\n",
    "                    best_settings = {\n",
    "                        'trees': n_trees,\n",
    "                        'depth': depth,\n",
    "                        'weight': weight,\n",
    "                        'threshold': threshold,\n",
    "                        'caught': caught,\n",
    "                        'false_alarms': false_alarms\n",
    "                    }\n",
    "\n",
    "print(\"Best settings:\", best_settings)\n",
    "print(f\"Recall: {best_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "461ab7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.52      0.63       159\n",
      "           1       0.21      0.49      0.29        41\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.50      0.50      0.46       200\n",
      "weighted avg       0.68      0.52      0.56       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[83 76]\n",
      " [21 20]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Build the RandomForestClassifer class on the best found parameters\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth = 10, class_weight={0:1, 1:5}, random_state=42).fit(X_train, y_train)\n",
    "probability = model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.30\n",
    "predictions = (probability >= threshold).astype(int)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "class_report = classification_report(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d113ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MinTransaction</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TotalSpent</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LoginFrequency</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MaxTransaction</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LoyaltyLength</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TransactionFrequency</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IncomeLevel</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FeedbackCount</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ComplaintCount</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isMale</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>InquiryCount</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MaritalStatus_Divorced</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ComplaintResolved</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ServiceUsage_Website</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ServiceUsage_Mobile App</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MaritalStatus_Widowed</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>InquiryUnresolved</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ServiceUsage_Online Banking</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ComplaintUnresolved</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MaritalStatus_Married</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MaritalStatus_Single</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FeedbackUnresolved</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InquiryResolved</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FeedbackResolved</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature  Importance\n",
       "4                MinTransaction        0.12\n",
       "3                    TotalSpent        0.12\n",
       "17               LoginFrequency        0.12\n",
       "5                MaxTransaction        0.11\n",
       "7                 LoyaltyLength        0.11\n",
       "0                           Age        0.10\n",
       "6          TransactionFrequency        0.05\n",
       "2                   IncomeLevel        0.03\n",
       "11                FeedbackCount        0.02\n",
       "14               ComplaintCount        0.02\n",
       "1                        isMale        0.02\n",
       "8                  InquiryCount        0.02\n",
       "18       MaritalStatus_Divorced        0.02\n",
       "15            ComplaintResolved        0.02\n",
       "24         ServiceUsage_Website        0.01\n",
       "22      ServiceUsage_Mobile App        0.01\n",
       "21        MaritalStatus_Widowed        0.01\n",
       "10            InquiryUnresolved        0.01\n",
       "23  ServiceUsage_Online Banking        0.01\n",
       "16          ComplaintUnresolved        0.01\n",
       "19        MaritalStatus_Married        0.01\n",
       "20         MaritalStatus_Single        0.01\n",
       "13           FeedbackUnresolved        0.01\n",
       "9               InquiryResolved        0.01\n",
       "12             FeedbackResolved        0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "display(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db1afd",
   "metadata": {},
   "source": [
    "***Observations:*** The features have no real weight. It tracks because of the low correlation across the board.\n",
    "***Why it Matters:*** The data collection is insufficient, please see recommendations at the top of the report. \n",
    "\n",
    "***Additional Investigation***\n",
    "After creating clusters, I add the Cluster to the Data to see if it would increase accuracy. It did but barely. No decrease in the false alarms.\n",
    "\n",
    "***Reasoning: ***\n",
    "Maybe the module can see a pattern between the clusters that would increase accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9b7de",
   "metadata": {},
   "source": [
    "Because of how inaccurate the model using RandomForest is, I decided to check it against XGBoost. The results were similar. Only 2 more caught. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "308b77e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost settings: {'trees': 200, 'depth': 3, 'weight': 5, 'threshold': 0.2, 'caught': np.int64(20), 'false_alarms': np.int64(72)}\n",
      "Recall: 0.49\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_recall = 0\n",
    "best_settings = {}\n",
    "\n",
    "for n_trees in [100, 200, 500]:\n",
    "    for depth in [3, 5, 10]:\n",
    "        for weight in [5, 10, 15, 20]:\n",
    "            for threshold in [0.2, 0.3, 0.4, 0.5]:\n",
    "                model = XGBClassifier(n_estimators=n_trees, \n",
    "                                       max_depth=depth, \n",
    "                                       scale_pos_weight=weight,\n",
    "                                       random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "                probs = model.predict_proba(X_test)[:, 1]\n",
    "                predictions = (probs >= threshold).astype(int)\n",
    "                \n",
    "                caught = confusion_matrix(y_test, predictions)[1, 1]\n",
    "                false_alarms = confusion_matrix(y_test, predictions)[0, 1]\n",
    "                recall = caught / 41\n",
    "                \n",
    "                if recall > best_recall and false_alarms < 80:\n",
    "                    best_recall = recall\n",
    "                    best_settings = {\n",
    "                        'trees': n_trees,\n",
    "                        'depth': depth,\n",
    "                        'weight': weight,\n",
    "                        'threshold': threshold,\n",
    "                        'caught': caught,\n",
    "                        'false_alarms': false_alarms\n",
    "                    }\n",
    "\n",
    "print(\"Best XGBoost settings:\", best_settings)\n",
    "print(f\"Recall: {best_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03f6c227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "[[87 72]\n",
      " [21 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.55      0.65       159\n",
      "           1       0.22      0.49      0.30        41\n",
      "\n",
      "    accuracy                           0.54       200\n",
      "   macro avg       0.51      0.52      0.48       200\n",
      "weighted avg       0.68      0.54      0.58       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=200, \n",
    "                       max_depth=3, \n",
    "                       scale_pos_weight=5,\n",
    "                       random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "predictions = (probs >= 0.2).astype(int)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
