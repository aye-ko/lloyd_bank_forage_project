{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64249dda",
   "metadata": {},
   "source": [
    "# Creating a Random Forest Classification Model. \n",
    "\n",
    "## Bottom Line Up Front: \n",
    "\n",
    "The correlation of the features are too low to get more accurate predictions. Currently predicting at 54% at best, might as well be a coin flip to predict who would churn or not.\n",
    "\n",
    " We need to collect better data. \n",
    "\n",
    "***Recommendation***\n",
    "\n",
    "I suggest the following: \n",
    "    - Actual Income amount, not just Low/Medium/High. This would have helped narrow down the tax bracket the customers who churn fall in, and tease out a potential reason for churning. \n",
    "    - Monthly spending to see if it is increasing, decreasing or flat.   Might offer insight into predicting who will churn. \n",
    "    - Interaction Quality not just count or resolved. Would answer how the customer felt when it was resolved. Ties in with Monthly Spending, did their spending decrease after an issue was reported, or after it stayed unresolved. \n",
    "    - Check if feedback is positive or negative. \n",
    "    - Consider noSQL to store what the feedback or complaint is, what are they inquiring about to see if customers who churn have the same issue.\n",
    "    - When was the issue reported, when was it resolved. Time to resolution would help me understand better if our customer wait times might be a problem. \n",
    "    - Login dates, not just frequency of login, would be helpful to see if they were logging in a lot at first then suddenly stopped, and maybe we can find out why they stopped by checking the correlation with the above feature recommendations. \n",
    "\n",
    "The current dataset captures what customers do but not how they feel about the service. I can calculate Customer Satisfaction Scores from the above features and see how that correlates to churn. \n",
    "\n",
    "With the actual income, I can determine what customers earning churn because from the clustering data, it seems like the lower earners, who spend the most are the ones leaving more so that those who login frequently and spend and complain less. See previous report for more detail. \n",
    "\n",
    "## Algorithm Selection\n",
    "Using Random Forest because while accuracy is important, the task specifies that the model must be interpretable to the stakeholders.\n",
    "Random Forest indicates which features mattered most in the decisions and we can show this to stakeholders that this is why the model made a prediction.\n",
    "\n",
    "XG Boost would be the most accurate, but lacks the interpretable aspect, with each decision tree correcting the one before it, tracing the specific prediction becomes tangled. Logistic Regression will be the easiest to explain but will not be as accurate as random forest. \n",
    "\n",
    "## Implementation:\n",
    "    - I will train the model on 80% of the available Customer_Data_Cleaned set and test it on the remaining 20%.\n",
    "\n",
    "    - target (y) is ChurnStatus. \n",
    "\n",
    "    - features (x) are all features except CustomerID because it's not important to the analysis, has no bearing whatsoever. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c91821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install libraries\n",
    "!python -m pip install --upgrade pip -q\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn openpyxl -q\n",
    "!pip install --upgrade openpyxl -q\n",
    "!pip install xgboost -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072b4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2979ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   CustomerID                   1000 non-null   int64  \n",
      " 1   Age                          1000 non-null   float64\n",
      " 2   isMale                       1000 non-null   int64  \n",
      " 3   IncomeLevel                  1000 non-null   int64  \n",
      " 4   ChurnStatus                  1000 non-null   int64  \n",
      " 5   TotalSpent                   1000 non-null   float64\n",
      " 6   MinTransaction               1000 non-null   float64\n",
      " 7   MaxTransaction               1000 non-null   float64\n",
      " 8   TransactionFrequency         1000 non-null   float64\n",
      " 9   LoyaltyLength                1000 non-null   float64\n",
      " 10  InquiryCount                 1000 non-null   float64\n",
      " 11  InquiryResolved              1000 non-null   float64\n",
      " 12  InquiryUnresolved            1000 non-null   float64\n",
      " 13  FeedbackCount                1000 non-null   float64\n",
      " 14  FeedbackResolved             1000 non-null   float64\n",
      " 15  FeedbackUnresolved           1000 non-null   float64\n",
      " 16  ComplaintCount               1000 non-null   float64\n",
      " 17  ComplaintResolved            1000 non-null   float64\n",
      " 18  ComplaintUnresolved          1000 non-null   float64\n",
      " 19  LoginFrequency               1000 non-null   float64\n",
      " 20  MaritalStatus_Divorced       1000 non-null   int64  \n",
      " 21  MaritalStatus_Married        1000 non-null   int64  \n",
      " 22  MaritalStatus_Single         1000 non-null   int64  \n",
      " 23  MaritalStatus_Widowed        1000 non-null   int64  \n",
      " 24  ServiceUsage_Mobile App      1000 non-null   int64  \n",
      " 25  ServiceUsage_Online Banking  1000 non-null   int64  \n",
      " 26  ServiceUsage_Website         1000 non-null   int64  \n",
      " 27  TotalUnresolved              1000 non-null   float64\n",
      " 28  Cluster                      1000 non-null   int64  \n",
      "dtypes: float64(17), int64(12)\n",
      "memory usage: 226.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>isMale</th>\n",
       "      <th>IncomeLevel</th>\n",
       "      <th>ChurnStatus</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>MinTransaction</th>\n",
       "      <th>MaxTransaction</th>\n",
       "      <th>TransactionFrequency</th>\n",
       "      <th>LoyaltyLength</th>\n",
       "      <th>InquiryCount</th>\n",
       "      <th>InquiryResolved</th>\n",
       "      <th>InquiryUnresolved</th>\n",
       "      <th>FeedbackCount</th>\n",
       "      <th>FeedbackResolved</th>\n",
       "      <th>FeedbackUnresolved</th>\n",
       "      <th>ComplaintCount</th>\n",
       "      <th>ComplaintResolved</th>\n",
       "      <th>ComplaintUnresolved</th>\n",
       "      <th>LoginFrequency</th>\n",
       "      <th>MaritalStatus_Divorced</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>MaritalStatus_Widowed</th>\n",
       "      <th>ServiceUsage_Mobile App</th>\n",
       "      <th>ServiceUsage_Online Banking</th>\n",
       "      <th>ServiceUsage_Website</th>\n",
       "      <th>TotalUnresolved</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.09</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.09</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.09</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.41</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.57</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID   Age  isMale  IncomeLevel  ChurnStatus  TotalSpent  \\\n",
       "0           1  1.23       1            1            0       -1.15   \n",
       "1           2  1.43       1            1            1        0.38   \n",
       "2           3 -1.66       1            1            0        0.59   \n",
       "3           4 -1.46       1            1            0       -0.47   \n",
       "4           5 -1.46       1            2            0        0.99   \n",
       "\n",
       "   MinTransaction  MaxTransaction  TransactionFrequency  LoyaltyLength  \\\n",
       "0            3.06            0.25                 -1.56          -1.89   \n",
       "1           -0.52            0.07                  0.75           0.96   \n",
       "2           -0.55            0.28                  0.36           0.28   \n",
       "3           -0.62           -0.07                 -0.02           0.10   \n",
       "4           -0.37            0.80                  1.13           0.86   \n",
       "\n",
       "   InquiryCount  InquiryResolved  InquiryUnresolved  FeedbackCount  \\\n",
       "0          1.34             2.09              -0.39          -0.62   \n",
       "1          1.34             2.09              -0.39          -0.62   \n",
       "2          1.34             2.09              -0.39          -0.62   \n",
       "3          3.27             2.09               2.41          -0.62   \n",
       "4         -0.59            -0.42              -0.39          -0.62   \n",
       "\n",
       "   FeedbackResolved  FeedbackUnresolved  ComplaintCount  ComplaintResolved  \\\n",
       "0             -0.47               -0.41           -0.61              -0.41   \n",
       "1             -0.47               -0.41           -0.61              -0.41   \n",
       "2             -0.47               -0.41           -0.61              -0.41   \n",
       "3             -0.47               -0.41           -0.61              -0.41   \n",
       "4             -0.47               -0.41           -0.61              -0.41   \n",
       "\n",
       "   ComplaintUnresolved  LoginFrequency  MaritalStatus_Divorced  \\\n",
       "0                -0.44            0.58                       0   \n",
       "1                -0.44           -1.49                       0   \n",
       "2                -0.44           -1.63                       0   \n",
       "3                -0.44           -1.70                       0   \n",
       "4                -0.44            1.07                       1   \n",
       "\n",
       "   MaritalStatus_Married  MaritalStatus_Single  MaritalStatus_Widowed  \\\n",
       "0                      0                     1                      0   \n",
       "1                      1                     0                      0   \n",
       "2                      0                     1                      0   \n",
       "3                      0                     0                      1   \n",
       "4                      0                     0                      0   \n",
       "\n",
       "   ServiceUsage_Mobile App  ServiceUsage_Online Banking  ServiceUsage_Website  \\\n",
       "0                        1                            0                     0   \n",
       "1                        0                            0                     1   \n",
       "2                        0                            0                     1   \n",
       "3                        0                            0                     1   \n",
       "4                        0                            0                     1   \n",
       "\n",
       "   TotalUnresolved  Cluster  \n",
       "0            -1.23        1  \n",
       "1            -1.23        8  \n",
       "2            -1.23        8  \n",
       "3             1.57        8  \n",
       "4            -1.23        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) # Set option to display all columns\n",
    "pd.set_option('display.float_format', '{:.2f}'.format) # Set float format to 2 decimal places\n",
    "\n",
    "# Load the cleaned customer data we previously created, and verify the info and the first few rows\n",
    "Customer_Data = pd.read_excel('Customer_Data_Cleaned.xlsx')\n",
    "Customer_Data.info()\n",
    "Customer_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836307fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "\n",
    "X = Customer_Data.drop(columns=['CustomerID', 'ChurnStatus'])\n",
    "y = Customer_Data['ChurnStatus']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, # 20% for testing\n",
    "                                                    random_state=42, # makes it reproducible same split every time\n",
    "                                                    stratify= y # keep churn ratio distributed and balanced in both sets\n",
    "                                                    )\n",
    "\n",
    "# # Verify the shape of the splits\n",
    "# print(\"X_train shape:\", X_train.shape)\n",
    "# print(\"X_test shape:\", X_test.shape)\n",
    "# print(\"y_train shape:\", y_train.shape)\n",
    "# print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf0729",
   "metadata": {},
   "source": [
    "***Reasoning:***\n",
    "\n",
    "When creating the for loop to check for hyperparameters, I could have used GridSearchCV but I wanted to evaluate for false alarms as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400cb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the for loop to tune hyperparameters\n",
    "best_recall = 0\n",
    "best_settings = {}\n",
    "\n",
    "for n_trees in [100, 200, 500]: # select number of trees\n",
    "    for depth in [5, 10, 20, None]: # select max depth\n",
    "        for weight in [1, 2, 5, 10]: # select class weight for churners\n",
    "            for threshold in [0.3, 0.4, 0.5]: # select probability threshold\n",
    "                model = RandomForestClassifier(n_estimators=n_trees, \n",
    "                                                max_depth=depth, \n",
    "                                                class_weight={0: 1, 1: weight},\n",
    "                                                random_state=42) # random state for reproducibility\n",
    "                model.fit(X_train, y_train)\n",
    "                probs = model.predict_proba(X_test)[:, 1]\n",
    "                predictions = (probs >= threshold).astype(int)\n",
    "                \n",
    "                caught = confusion_matrix(y_test, predictions)[1, 1]\n",
    "                false_alarms = confusion_matrix(y_test, predictions)[0, 1]\n",
    "                recall = caught / 41 # there are 41 actual churners in the test set, caught divided by total actual churners\n",
    "                \n",
    "                # Only save if this is the best so far AND false alarms are reasonable\n",
    "                if recall > best_recall and false_alarms < 80: # stop if more than 80 false alarms, store settings\n",
    "                    best_recall = recall\n",
    "                    best_settings = {\n",
    "                        'trees': n_trees,\n",
    "                        'depth': depth,\n",
    "                        'weight': weight,\n",
    "                        'threshold': threshold,\n",
    "                        'caught': caught,\n",
    "                        'false_alarms': false_alarms\n",
    "                    }\n",
    "\n",
    "print(\"Best settings:\", best_settings)\n",
    "print(f\"Recall: {best_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ab7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Build the RandomForestClassifer class on the best found parameters\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth = 10, class_weight={0:1, 1:5}, random_state=42).fit(X_train, y_train)\n",
    "probability = model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.30\n",
    "predictions = (probability >= threshold).astype(int)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "class_report = classification_report(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "display(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db1afd",
   "metadata": {},
   "source": [
    "***Observations:*** The features have no real weight. It tracks because of the low correlation across the board.\n",
    "***Why it Matters:*** The data collection is insufficient, please see recommendations at the top of the report. \n",
    "\n",
    "***Additional Investigation***\n",
    "After creating clusters, I add the Cluster to the Data to see if it would increase accuracy. It did but barely. No decrease in the false alarms.\n",
    "\n",
    "***Reasoning: ***\n",
    "Maybe the module can see a pattern between the clusters that would increase accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster to features\n",
    "X_with_cluster = X.copy()\n",
    "X_with_cluster['Cluster'] = Customer_Data['Cluster']\n",
    "\n",
    "# Split again with new features\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_with_cluster, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train Random Forest with clusters\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=10, \n",
    "                                class_weight={0:1, 1:5}, random_state=42)\n",
    "model.fit(X_train_c, y_train_c)\n",
    "probs = model.predict_proba(X_test_c)[:, 1]\n",
    "predictions = (probs >= 0.3).astype(int)\n",
    "\n",
    "print(\"WITH clusters:\")\n",
    "print(confusion_matrix(y_test_c, predictions))\n",
    "print(f\"Churners caught: {confusion_matrix(y_test_c, predictions)[1,1]}/41\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9b7de",
   "metadata": {},
   "source": [
    "Because of how inaccurate the model using RandomForest is, I decided to check it against XGBoost. The results were similar. Only 2 more caught. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_recall = 0\n",
    "best_settings = {}\n",
    "\n",
    "for n_trees in [100, 200, 500]:\n",
    "    for depth in [3, 5, 10]:\n",
    "        for weight in [5, 10, 15, 20]:\n",
    "            for threshold in [0.2, 0.3, 0.4, 0.5]:\n",
    "                model = XGBClassifier(n_estimators=n_trees, \n",
    "                                       max_depth=depth, \n",
    "                                       scale_pos_weight=weight,\n",
    "                                       random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "                probs = model.predict_proba(X_test)[:, 1]\n",
    "                predictions = (probs >= threshold).astype(int)\n",
    "                \n",
    "                caught = confusion_matrix(y_test, predictions)[1, 1]\n",
    "                false_alarms = confusion_matrix(y_test, predictions)[0, 1]\n",
    "                recall = caught / 41\n",
    "                \n",
    "                if recall > best_recall and false_alarms < 80:\n",
    "                    best_recall = recall\n",
    "                    best_settings = {\n",
    "                        'trees': n_trees,\n",
    "                        'depth': depth,\n",
    "                        'weight': weight,\n",
    "                        'threshold': threshold,\n",
    "                        'caught': caught,\n",
    "                        'false_alarms': false_alarms\n",
    "                    }\n",
    "\n",
    "print(\"Best XGBoost settings:\", best_settings)\n",
    "print(f\"Recall: {best_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=200, \n",
    "                       max_depth=3, \n",
    "                       scale_pos_weight=5,\n",
    "                       random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "predictions = (probs >= 0.2).astype(int)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(n_estimators=200, max_depth=3, \n",
    "                           scale_pos_weight=5, random_state=42)\n",
    "model_xgb.fit(X_train_c, y_train_c)\n",
    "probs = model_xgb.predict_proba(X_test_c)[:, 1]\n",
    "predictions = (probs >= 0.2).astype(int)\n",
    "\n",
    "print(\"XGBoost WITH clusters:\")\n",
    "print(confusion_matrix(y_test_c, predictions))\n",
    "print(f\"Churners caught: {confusion_matrix(y_test_c, predictions)[1,1]}/41\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
